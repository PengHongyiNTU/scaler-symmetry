{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(16.6607)\n",
      "tensor(0.)\n",
      "tensor(-14.4691)\n",
      "tensor(0.)\n",
      "tensor(-3.2008)\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "from utils import build_mlp_model\n",
    "import torch\n",
    "model_1 = build_mlp_model()\n",
    "model_2 = build_mlp_model()\n",
    "from utils import initialization_with_seed\n",
    "model_1 = initialization_with_seed(model_1, seed=42)\n",
    "model_2 = initialization_with_seed(model_2, seed=65)\n",
    "state_dict_1 = model_1.state_dict()\n",
    "state_dict_2 = model_2.state_dict()\n",
    "for key in state_dict_1.keys():\n",
    "    print(torch.sum(state_dict_1[key] - state_dict_2[key]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import prepare_dataset\n",
    "from torchmetrics import Accuracy\n",
    "trainset, testset = prepare_dataset(\"MNIST\", model_type=\"MLP\")\n",
    "accuracy = Accuracy(task=\"multiclass\", num_classes=10)\n",
    "accuracy = accuracy.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import histogram, rec\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from typing import Literal\n",
    "def train(model: nn.Module, \n",
    "                  train_loader: DataLoader, \n",
    "                  optimizer: torch.optim.Optimizer, \n",
    "                  criterion: nn.Module, \n",
    "                  max_epochs: int, \n",
    "                  device: Literal[\"cpu\", \"cuda:2\"]):\n",
    "            model.train()\n",
    "            model.to(device)\n",
    "            total_loss = 0\n",
    "            pbar = tqdm(train_loader)\n",
    "            records = []\n",
    "            for epoch in range(max_epochs):\n",
    "                for inputs, targets in pbar:\n",
    "                    inputs = inputs.to(device)\n",
    "                    targets = targets.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    total_loss += loss.item()\n",
    "                    accuracy(outputs, targets)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    pbar.set_description(f\"Epoch: {epoch+1}/{max_epochs}, Step Loss: {loss.item():.4f}\")\n",
    "                records.append({'Train Loss': total_loss/len(train_loader), \n",
    "                                'Train Acc': accuracy.compute().item()})\n",
    "            return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 10\n",
    "TRAIN_BATCH_SIZE = 256\n",
    "TEST_BATCH_SIZE = 1000\n",
    "train_loader = DataLoader(trainset, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(testset, batch_size=TEST_BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model_1.parameters(), lr=1e-1)\n",
    "optimizer2 = torch.optim.Adam(model_2.parameters(), lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10, Step Loss: 6.6932:   7%|â–‹         | 16/235 [00:56<12:48,  3.51s/it] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/hypeng/Research/notebooks_experiments/permute_test.ipynb Cell 6\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22576562616e6b2e4e54552e3441313030227d/home/hypeng/Research/notebooks_experiments/permute_test.ipynb#X66sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m device \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22576562616e6b2e4e54552e3441313030227d/home/hypeng/Research/notebooks_experiments/permute_test.ipynb#X66sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(device)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22576562616e6b2e4e54552e3441313030227d/home/hypeng/Research/notebooks_experiments/permute_test.ipynb#X66sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m model_1_records \u001b[39m=\u001b[39m train(model_1, train_loader, optimizer, criterion, MAX_EPOCHS, device)\n",
      "\u001b[1;32m/home/hypeng/Research/notebooks_experiments/permute_test.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22576562616e6b2e4e54552e3441313030227d/home/hypeng/Research/notebooks_experiments/permute_test.ipynb#X66sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m records \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22576562616e6b2e4e54552e3441313030227d/home/hypeng/Research/notebooks_experiments/permute_test.ipynb#X66sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(max_epochs):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22576562616e6b2e4e54552e3441313030227d/home/hypeng/Research/notebooks_experiments/permute_test.ipynb#X66sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mfor\u001b[39;00m inputs, targets \u001b[39min\u001b[39;00m pbar:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22576562616e6b2e4e54552e3441313030227d/home/hypeng/Research/notebooks_experiments/permute_test.ipynb#X66sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m         inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22576562616e6b2e4e54552e3441313030227d/home/hypeng/Research/notebooks_experiments/permute_test.ipynb#X66sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m         targets \u001b[39m=\u001b[39m targets\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/ray/lib/python3.9/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ray/lib/python3.9/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/ray/lib/python3.9/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/ray/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/ray/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/ray/lib/python3.9/site-packages/torchvision/datasets/mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    142\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(img\u001b[39m.\u001b[39mnumpy(), mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(img)\n\u001b[1;32m    147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m~/miniconda3/envs/ray/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/ray/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ray/lib/python3.9/site-packages/torchvision/transforms/v2/_container.py:53\u001b[0m, in \u001b[0;36mCompose.forward\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m     51\u001b[0m needs_unpacking \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(inputs) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     52\u001b[0m \u001b[39mfor\u001b[39;00m transform \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m---> 53\u001b[0m     outputs \u001b[39m=\u001b[39m transform(\u001b[39m*\u001b[39;49minputs)\n\u001b[1;32m     54\u001b[0m     inputs \u001b[39m=\u001b[39m outputs \u001b[39mif\u001b[39;00m needs_unpacking \u001b[39melse\u001b[39;00m (outputs,)\n\u001b[1;32m     55\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/miniconda3/envs/ray/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/ray/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ray/lib/python3.9/site-packages/torchvision/transforms/v2/_transform.py:50\u001b[0m, in \u001b[0;36mTransform.forward\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m     45\u001b[0m needs_transform_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_needs_transform_list(flat_inputs)\n\u001b[1;32m     46\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_params(\n\u001b[1;32m     47\u001b[0m     [inpt \u001b[39mfor\u001b[39;00m (inpt, needs_transform) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(flat_inputs, needs_transform_list) \u001b[39mif\u001b[39;00m needs_transform]\n\u001b[1;32m     48\u001b[0m )\n\u001b[0;32m---> 50\u001b[0m flat_outputs \u001b[39m=\u001b[39m [\n\u001b[1;32m     51\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transform(inpt, params) \u001b[39mif\u001b[39;00m needs_transform \u001b[39melse\u001b[39;00m inpt\n\u001b[1;32m     52\u001b[0m     \u001b[39mfor\u001b[39;00m (inpt, needs_transform) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(flat_inputs, needs_transform_list)\n\u001b[1;32m     53\u001b[0m ]\n\u001b[1;32m     55\u001b[0m \u001b[39mreturn\u001b[39;00m tree_unflatten(flat_outputs, spec)\n",
      "File \u001b[0;32m~/miniconda3/envs/ray/lib/python3.9/site-packages/torchvision/transforms/v2/_transform.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     45\u001b[0m needs_transform_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_needs_transform_list(flat_inputs)\n\u001b[1;32m     46\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_params(\n\u001b[1;32m     47\u001b[0m     [inpt \u001b[39mfor\u001b[39;00m (inpt, needs_transform) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(flat_inputs, needs_transform_list) \u001b[39mif\u001b[39;00m needs_transform]\n\u001b[1;32m     48\u001b[0m )\n\u001b[1;32m     50\u001b[0m flat_outputs \u001b[39m=\u001b[39m [\n\u001b[0;32m---> 51\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transform(inpt, params) \u001b[39mif\u001b[39;00m needs_transform \u001b[39melse\u001b[39;00m inpt\n\u001b[1;32m     52\u001b[0m     \u001b[39mfor\u001b[39;00m (inpt, needs_transform) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(flat_inputs, needs_transform_list)\n\u001b[1;32m     53\u001b[0m ]\n\u001b[1;32m     55\u001b[0m \u001b[39mreturn\u001b[39;00m tree_unflatten(flat_outputs, spec)\n",
      "File \u001b[0;32m~/miniconda3/envs/ray/lib/python3.9/site-packages/torchvision/transforms/v2/_geometry.py:642\u001b[0m, in \u001b[0;36mRandomRotation._transform\u001b[0;34m(self, inpt, params)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_transform\u001b[39m(\u001b[39mself\u001b[39m, inpt: Any, params: Dict[\u001b[39mstr\u001b[39m, Any]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    641\u001b[0m     fill \u001b[39m=\u001b[39m _get_fill(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fill, \u001b[39mtype\u001b[39m(inpt))\n\u001b[0;32m--> 642\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_kernel(\n\u001b[1;32m    643\u001b[0m         F\u001b[39m.\u001b[39;49mrotate,\n\u001b[1;32m    644\u001b[0m         inpt,\n\u001b[1;32m    645\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams,\n\u001b[1;32m    646\u001b[0m         interpolation\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minterpolation,\n\u001b[1;32m    647\u001b[0m         expand\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexpand,\n\u001b[1;32m    648\u001b[0m         center\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcenter,\n\u001b[1;32m    649\u001b[0m         fill\u001b[39m=\u001b[39;49mfill,\n\u001b[1;32m    650\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/ray/lib/python3.9/site-packages/torchvision/transforms/v2/_transform.py:35\u001b[0m, in \u001b[0;36mTransform._call_kernel\u001b[0;34m(self, functional, inpt, *args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_kernel\u001b[39m(\u001b[39mself\u001b[39m, functional: Callable, inpt: Any, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m     34\u001b[0m     kernel \u001b[39m=\u001b[39m _get_kernel(functional, \u001b[39mtype\u001b[39m(inpt), allow_passthrough\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 35\u001b[0m     \u001b[39mreturn\u001b[39;00m kernel(inpt, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/ray/lib/python3.9/site-packages/torchvision/transforms/v2/functional/_utils.py:31\u001b[0m, in \u001b[0;36m_kernel_tv_tensor_wrapper.<locals>.wrapper\u001b[0;34m(inpt, *args, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(kernel)\n\u001b[1;32m     21\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(inpt, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     22\u001b[0m     \u001b[39m# If you're wondering whether we could / should get rid of this wrapper,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[39m# lost after the first operation due to our own __torch_function__\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     \u001b[39m# logic.\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     output \u001b[39m=\u001b[39m kernel(inpt\u001b[39m.\u001b[39;49mas_subclass(torch\u001b[39m.\u001b[39;49mTensor), \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     32\u001b[0m     \u001b[39mreturn\u001b[39;00m tv_tensors\u001b[39m.\u001b[39mwrap(output, like\u001b[39m=\u001b[39minpt)\n",
      "File \u001b[0;32m~/miniconda3/envs/ray/lib/python3.9/site-packages/torchvision/transforms/v2/functional/_geometry.py:995\u001b[0m, in \u001b[0;36mrotate_image\u001b[0;34m(image, angle, interpolation, expand, center, fill)\u001b[0m\n\u001b[1;32m    993\u001b[0m dtype \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39mdtype \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mis_floating_point(image) \u001b[39melse\u001b[39;00m torch\u001b[39m.\u001b[39mfloat32\n\u001b[1;32m    994\u001b[0m theta \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(matrix, dtype\u001b[39m=\u001b[39mdtype, device\u001b[39m=\u001b[39mimage\u001b[39m.\u001b[39mdevice)\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m)\n\u001b[0;32m--> 995\u001b[0m grid \u001b[39m=\u001b[39m _affine_grid(theta, w\u001b[39m=\u001b[39;49mwidth, h\u001b[39m=\u001b[39;49mheight, ow\u001b[39m=\u001b[39;49mow, oh\u001b[39m=\u001b[39;49moh)\n\u001b[1;32m    996\u001b[0m output \u001b[39m=\u001b[39m _apply_grid_transform(image, grid, interpolation\u001b[39m.\u001b[39mvalue, fill\u001b[39m=\u001b[39mfill)\n\u001b[1;32m    998\u001b[0m new_height, new_width \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m:]\n",
      "File \u001b[0;32m~/miniconda3/envs/ray/lib/python3.9/site-packages/torchvision/transforms/v2/functional/_geometry.py:649\u001b[0m, in \u001b[0;36m_affine_grid\u001b[0;34m(theta, w, h, ow, oh)\u001b[0m\n\u001b[1;32m    646\u001b[0m base_grid[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39m2\u001b[39m]\u001b[39m.\u001b[39mfill_(\u001b[39m1\u001b[39m)\n\u001b[1;32m    648\u001b[0m rescaled_theta \u001b[39m=\u001b[39m theta\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mdiv_(torch\u001b[39m.\u001b[39mtensor([\u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m w, \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m h], dtype\u001b[39m=\u001b[39mdtype, device\u001b[39m=\u001b[39mdevice))\n\u001b[0;32m--> 649\u001b[0m output_grid \u001b[39m=\u001b[39m base_grid\u001b[39m.\u001b[39;49mview(\u001b[39m1\u001b[39;49m, oh \u001b[39m*\u001b[39;49m ow, \u001b[39m3\u001b[39;49m)\u001b[39m.\u001b[39;49mbmm(rescaled_theta)\n\u001b[1;32m    650\u001b[0m \u001b[39mreturn\u001b[39;00m output_grid\u001b[39m.\u001b[39mview(\u001b[39m1\u001b[39m, oh, ow, \u001b[39m2\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "model_1_records = train(model_1, train_loader, optimizer, criterion, MAX_EPOCHS, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = build_mlp_model()\n",
    "new_model.load_state_dict(model_1.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(\n",
    "    model: nn.Module,\n",
    "    test_loader: DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    device: Literal[\"cpu\", \"cuda:2:2:2:2\"],\n",
    "):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    total_loss = 0\n",
    "    pbar = tqdm(test_loader)\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in pbar:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "            accuracy(outputs, targets)\n",
    "    return {\n",
    "        \"Testl Loss\": total_loss / len(test_loader),\n",
    "        \"Test Acc\": accuracy.compute().item(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.06it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Testl Loss': 0.2260461539030075, 'Test Acc': 0.8295442461967468}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(new_model, test_loader, criterion, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for name, param in new_model.named_parameters():\n",
    "    print(torch.sum(param.data - model_1.state_dict()[name].data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  4.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Testl Loss': 0.2260461539030075, 'Test Acc': 0.8312322497367859}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model_1, test_loader, criterion, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10, Step Loss: 1.1503, Step Acc: 0.6086: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.02s/it]\n",
      "Epoch: 2/10, Step Loss: 0.5910, Step Acc: 0.8010: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.02s/it]\n",
      "Epoch: 3/10, Step Loss: 0.6078, Step Acc: 0.7780: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.01s/it]\n",
      "Epoch: 4/10, Step Loss: 0.4363, Step Acc: 0.8651: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:29<00:00,  1.00it/s]\n",
      "Epoch: 5/10, Step Loss: 0.3407, Step Acc: 0.9013: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:29<00:00,  1.03it/s]\n",
      "Epoch: 6/10, Step Loss: 0.3180, Step Acc: 0.9030: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:29<00:00,  1.02it/s]\n",
      "Epoch: 7/10, Step Loss: 0.3054, Step Acc: 0.9243: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:29<00:00,  1.01it/s]\n",
      "Epoch: 8/10, Step Loss: 0.3605, Step Acc: 0.8947: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:28<00:00,  1.05it/s]\n",
      "Epoch: 9/10, Step Loss: 0.3017, Step Acc: 0.9030: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:28<00:00,  1.05it/s]\n",
      "Epoch: 10/10, Step Loss: 0.2532, Step Acc: 0.9211: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:28<00:00,  1.04it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(MAX_EPOCHS):\n",
    "    train(model_2, train_loader, optimizer2, criterion, epoch, MAX_EPOCHS, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [04:36<00:00,  9.22s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Testl Loss': 2.302582621574402, 'Test Acc': 0.09847778081893921}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model_2, train_loader, criterion, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.WEIGHT: Diff: 4709.8525390625\n",
      "0.BIAS: Diff: 3.2348155975341797\n",
      "2.WEIGHT: Diff: 1394.478515625\n",
      "2.BIAS: Diff: 8.667121887207031\n",
      "4.WEIGHT: Diff: 157.3886260986328\n",
      "4.BIAS: Diff: 0.6120636463165283\n"
     ]
    }
   ],
   "source": [
    "state_dict_1 = model_1.state_dict()\n",
    "state_dict_2 = model_2.state_dict()\n",
    "for key in state_dict_1.keys():\n",
    "    diff = torch.sum(torch.abs(state_dict_1[key] - state_dict_2[key]))\n",
    "    print(f\"{key.upper()}: Diff: {diff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Testl Loss': 0.07838473487645388, 'Test Acc': 0.947195291519165}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0\n",
    "from interpolate import interpolate_weights\n",
    "new_state_dict = interpolate_weights(state_dict_1, state_dict_2, alpha)\n",
    "model_1.load_state_dict(new_state_dict)\n",
    "test(model_1, test_loader, criterion, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0: Cost before: 2543.345947265625, Cost after: 1425.186279296875\n",
      "Layer 1: Cost before: 2463.74755859375, Cost after: 1404.76025390625\n",
      "[array([ 17,  88, 119,  92, 127, 116, 122,  54,  84,   4,  24, 102,   9,\n",
      "        81,  19,  60,  27,  61, 104,  63,   1,  21,  75,  78,  51,  85,\n",
      "       120,  10,  98,  13,  44,  66,  36,  12, 114, 113,  64,  86,   6,\n",
      "        45,  42, 109,  76,  79,  57,  28,  90,   5,  11,  25, 100, 111,\n",
      "        16,  22,  18,  68,  94, 101, 103,  74,  73,  56,  83, 105,  95,\n",
      "       107,  47,  39,  38, 121,  30, 117,  53,  29, 110, 125,  80,  37,\n",
      "        32,  20,  58,  97,  77,  15,  91,  72,  48,  52,  26, 126,  41,\n",
      "        67,  33,   8,  70,  50,   7,   2,  35,  40,  69,  46,  89, 106,\n",
      "        71,  93,  31,  59,  82,  23, 112,  65,  14,  96, 123,  62, 118,\n",
      "       124,  49,   0,  55,  34, 108,  99,  43,   3,  87, 115])]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/hypeng/Research/notebooks_experiments/permute_test.ipynb Cell 17\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22576562616e6b2e4e54552e3441313030227d/home/hypeng/Research/notebooks_experiments/permute_test.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m valset \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mSubset(trainset, \u001b[39mrange\u001b[39m(\u001b[39m500\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22576562616e6b2e4e54552e3441313030227d/home/hypeng/Research/notebooks_experiments/permute_test.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m val_loader \u001b[39m=\u001b[39m DataLoader(valset, batch_size\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22576562616e6b2e4e54552e3441313030227d/home/hypeng/Research/notebooks_experiments/permute_test.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m new_state_dict \u001b[39m=\u001b[39m match_and_permute(build_mlp_model, state_dict_1, state_dict_2, \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22576562616e6b2e4e54552e3441313030227d/home/hypeng/Research/notebooks_experiments/permute_test.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m                                    val_loader, device\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22576562616e6b2e4e54552e3441313030227d/home/hypeng/Research/notebooks_experiments/permute_test.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m model_1\u001b[39m.\u001b[39mload_state_dict(new_state_dict)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22576562616e6b2e4e54552e3441313030227d/home/hypeng/Research/notebooks_experiments/permute_test.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m test(model_1, test_loader, criterion, device\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Research/notebooks_experiments/permute.py:211\u001b[0m, in \u001b[0;36mmatch_and_permute\u001b[0;34m(model_builder, state_dict_1, state_dict_2, val_loader, device, activation_types)\u001b[0m\n\u001b[1;32m    209\u001b[0m model \u001b[39m=\u001b[39m model_builder()\n\u001b[1;32m    210\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(state_dict_2)\n\u001b[0;32m--> 211\u001b[0m new_state_dict \u001b[39m=\u001b[39m model_permutation(model, permutation_mappings)\n\u001b[1;32m    212\u001b[0m \u001b[39mreturn\u001b[39;00m new_state_dict\n",
      "File \u001b[0;32m~/Research/notebooks_experiments/permute.py:173\u001b[0m, in \u001b[0;36mmodel_permutation\u001b[0;34m(model, permutation_mappings)\u001b[0m\n\u001b[1;32m    171\u001b[0m         linear_layers\u001b[39m.\u001b[39mappend(module)\n\u001b[1;32m    172\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(linear_layers) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m--> 173\u001b[0m     permutation \u001b[39m=\u001b[39m permutation_mappings[i]\n\u001b[1;32m    174\u001b[0m     linear_layers[i]\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m linear_layers[i]\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mdata[permutation]\n\u001b[1;32m    175\u001b[0m     \u001b[39mif\u001b[39;00m linear_layers[i]\u001b[39m.\u001b[39mbias \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from permute import match_and_permute\n",
    "valset = torch.utils.data.Subset(trainset, range(500))\n",
    "val_loader = DataLoader(valset, batch_size=100, shuffle=False)\n",
    "new_state_dict = match_and_permute(build_mlp_model, state_dict_1, state_dict_2, \n",
    "                                   val_loader, device=\"cuda\")\n",
    "\n",
    "model_1.load_state_dict(new_state_dict)\n",
    "test(model_1, test_loader, criterion, device=\"cuda\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ray",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
