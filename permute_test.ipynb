{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(16.6607)\n",
      "tensor(0.)\n",
      "tensor(-14.4691)\n",
      "tensor(0.)\n",
      "tensor(-3.2008)\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "from utils import build_mlp_model\n",
    "import torch\n",
    "model_1 = build_mlp_model()\n",
    "model_2 = build_mlp_model()\n",
    "from utils import initialization_with_seed\n",
    "model_1 = initialization_with_seed(model_1, seed=42)\n",
    "model_2 = initialization_with_seed(model_2, seed=65)\n",
    "state_dict_1 = model_1.state_dict()\n",
    "state_dict_2 = model_2.state_dict()\n",
    "for key in state_dict_1.keys():\n",
    "    print(torch.sum(state_dict_1[key] - state_dict_2[key]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import prepare_dataset\n",
    "from torchmetrics import Accuracy\n",
    "trainset, testset = prepare_dataset(\"MNIST\", model_type=\"MLP\")\n",
    "accuracy = Accuracy(task=\"multiclass\", num_classes=10)\n",
    "accuracy = accuracy.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from typing import Literal\n",
    "def train(model: nn.Module, \n",
    "                  train_loader: DataLoader, \n",
    "                  optimizer: torch.optim.Optimizer, \n",
    "                  criterion: nn.Module,\n",
    "                  epoch: int, \n",
    "                  max_epochs: int, \n",
    "                  device: Literal[\"cpu\", \"cuda\"]):\n",
    "            model.train()\n",
    "            model.to(device)\n",
    "            total_loss = 0\n",
    "            pbar = tqdm(train_loader)\n",
    "            for inputs, targets in pbar:\n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                total_loss += loss.item()\n",
    "                acc = accuracy(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                pbar.set_description(f\"Epoch: {epoch+1}/{max_epochs}, Step Loss: {loss.item():.4f}, Step Acc: {acc.item():.4f}\")\n",
    "            return {'Train Loss': total_loss/len(train_loader), \n",
    "                    'Train Acc': accuracy.compute().item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 5\n",
    "TRAIN_BATCH_SIZE = 2048\n",
    "TEST_BATCH_SIZE = 1000\n",
    "train_loader = DataLoader(trainset, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(testset, batch_size=TEST_BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model_1.parameters(), lr=1e-1)\n",
    "optimizer2 = torch.optim.SGD(model_2.parameters(), lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5, Step Loss: 2.7604, Step Acc: 0.1992:  40%|████      | 12/30 [02:48<03:43, 12.43s/it]"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_1_history = []\n",
    "for epoch in range(MAX_EPOCHS):\n",
    "    result = train(model_1, train_loader, optimizer, criterion, epoch, MAX_EPOCHS, device)\n",
    "    model_1_history.append(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = build_mlp_model()\n",
    "new_model.load_state_dict(model_1.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(\n",
    "    model: nn.Module,\n",
    "    test_loader: DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    device: Literal[\"cpu\", \"cuda\"],\n",
    "):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    total_loss = 0\n",
    "    pbar = tqdm(test_loader)\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in pbar:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "            accuracy(outputs, targets)\n",
    "    return {\n",
    "        \"Testl Loss\": total_loss / len(test_loader),\n",
    "        \"Test Acc\": accuracy.compute().item(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.06it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Testl Loss': 0.2260461539030075, 'Test Acc': 0.8295442461967468}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(new_model, test_loader, criterion, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for name, param in new_model.named_parameters():\n",
    "    print(torch.sum(param.data - model_1.state_dict()[name].data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Testl Loss': 0.2260461539030075, 'Test Acc': 0.8312322497367859}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model_1, test_loader, criterion, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10, Step Loss: 1.1503, Step Acc: 0.6086: 100%|██████████| 30/30 [00:30<00:00,  1.02s/it]\n",
      "Epoch: 2/10, Step Loss: 0.5910, Step Acc: 0.8010: 100%|██████████| 30/30 [00:30<00:00,  1.02s/it]\n",
      "Epoch: 3/10, Step Loss: 0.6078, Step Acc: 0.7780: 100%|██████████| 30/30 [00:30<00:00,  1.01s/it]\n",
      "Epoch: 4/10, Step Loss: 0.4363, Step Acc: 0.8651: 100%|██████████| 30/30 [00:29<00:00,  1.00it/s]\n",
      "Epoch: 5/10, Step Loss: 0.3407, Step Acc: 0.9013: 100%|██████████| 30/30 [00:29<00:00,  1.03it/s]\n",
      "Epoch: 6/10, Step Loss: 0.3180, Step Acc: 0.9030: 100%|██████████| 30/30 [00:29<00:00,  1.02it/s]\n",
      "Epoch: 7/10, Step Loss: 0.3054, Step Acc: 0.9243: 100%|██████████| 30/30 [00:29<00:00,  1.01it/s]\n",
      "Epoch: 8/10, Step Loss: 0.3605, Step Acc: 0.8947: 100%|██████████| 30/30 [00:28<00:00,  1.05it/s]\n",
      "Epoch: 9/10, Step Loss: 0.3017, Step Acc: 0.9030: 100%|██████████| 30/30 [00:28<00:00,  1.05it/s]\n",
      "Epoch: 10/10, Step Loss: 0.2532, Step Acc: 0.9211: 100%|██████████| 30/30 [00:28<00:00,  1.04it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(MAX_EPOCHS):\n",
    "    train(model_2, train_loader, optimizer2, criterion, epoch, MAX_EPOCHS, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [04:36<00:00,  9.22s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Testl Loss': 2.302582621574402, 'Test Acc': 0.09847778081893921}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model_2, train_loader, criterion, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.WEIGHT: Diff: 4709.8525390625\n",
      "0.BIAS: Diff: 3.2348155975341797\n",
      "2.WEIGHT: Diff: 1394.478515625\n",
      "2.BIAS: Diff: 8.667121887207031\n",
      "4.WEIGHT: Diff: 157.3886260986328\n",
      "4.BIAS: Diff: 0.6120636463165283\n"
     ]
    }
   ],
   "source": [
    "state_dict_1 = model_1.state_dict()\n",
    "state_dict_2 = model_2.state_dict()\n",
    "for key in state_dict_1.keys():\n",
    "    diff = torch.sum(torch.abs(state_dict_1[key] - state_dict_2[key]))\n",
    "    print(f\"{key.upper()}: Diff: {diff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Testl Loss': 0.07838473487645388, 'Test Acc': 0.947195291519165}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0\n",
    "from interpolate import interpolate_weights\n",
    "new_state_dict = interpolate_weights(state_dict_1, state_dict_2, alpha)\n",
    "model_1.load_state_dict(new_state_dict)\n",
    "test(model_1, test_loader, criterion, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0: Cost before: 2543.345947265625, Cost after: 1425.186279296875\n",
      "Layer 1: Cost before: 2463.74755859375, Cost after: 1404.76025390625\n",
      "[array([ 17,  88, 119,  92, 127, 116, 122,  54,  84,   4,  24, 102,   9,\n",
      "        81,  19,  60,  27,  61, 104,  63,   1,  21,  75,  78,  51,  85,\n",
      "       120,  10,  98,  13,  44,  66,  36,  12, 114, 113,  64,  86,   6,\n",
      "        45,  42, 109,  76,  79,  57,  28,  90,   5,  11,  25, 100, 111,\n",
      "        16,  22,  18,  68,  94, 101, 103,  74,  73,  56,  83, 105,  95,\n",
      "       107,  47,  39,  38, 121,  30, 117,  53,  29, 110, 125,  80,  37,\n",
      "        32,  20,  58,  97,  77,  15,  91,  72,  48,  52,  26, 126,  41,\n",
      "        67,  33,   8,  70,  50,   7,   2,  35,  40,  69,  46,  89, 106,\n",
      "        71,  93,  31,  59,  82,  23, 112,  65,  14,  96, 123,  62, 118,\n",
      "       124,  49,   0,  55,  34, 108,  99,  43,   3,  87, 115])]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/hypeng/Research/notebooks_experiments/permute_test.ipynb Cell 17\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22576562616e6b2e4e54552e3441313030227d/home/hypeng/Research/notebooks_experiments/permute_test.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m valset \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mSubset(trainset, \u001b[39mrange\u001b[39m(\u001b[39m500\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22576562616e6b2e4e54552e3441313030227d/home/hypeng/Research/notebooks_experiments/permute_test.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m val_loader \u001b[39m=\u001b[39m DataLoader(valset, batch_size\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22576562616e6b2e4e54552e3441313030227d/home/hypeng/Research/notebooks_experiments/permute_test.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m new_state_dict \u001b[39m=\u001b[39m match_and_permute(build_mlp_model, state_dict_1, state_dict_2, \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22576562616e6b2e4e54552e3441313030227d/home/hypeng/Research/notebooks_experiments/permute_test.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m                                    val_loader, device\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22576562616e6b2e4e54552e3441313030227d/home/hypeng/Research/notebooks_experiments/permute_test.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m model_1\u001b[39m.\u001b[39mload_state_dict(new_state_dict)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22576562616e6b2e4e54552e3441313030227d/home/hypeng/Research/notebooks_experiments/permute_test.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m test(model_1, test_loader, criterion, device\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Research/notebooks_experiments/permute.py:211\u001b[0m, in \u001b[0;36mmatch_and_permute\u001b[0;34m(model_builder, state_dict_1, state_dict_2, val_loader, device, activation_types)\u001b[0m\n\u001b[1;32m    209\u001b[0m model \u001b[39m=\u001b[39m model_builder()\n\u001b[1;32m    210\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(state_dict_2)\n\u001b[0;32m--> 211\u001b[0m new_state_dict \u001b[39m=\u001b[39m model_permutation(model, permutation_mappings)\n\u001b[1;32m    212\u001b[0m \u001b[39mreturn\u001b[39;00m new_state_dict\n",
      "File \u001b[0;32m~/Research/notebooks_experiments/permute.py:173\u001b[0m, in \u001b[0;36mmodel_permutation\u001b[0;34m(model, permutation_mappings)\u001b[0m\n\u001b[1;32m    171\u001b[0m         linear_layers\u001b[39m.\u001b[39mappend(module)\n\u001b[1;32m    172\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(linear_layers) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m--> 173\u001b[0m     permutation \u001b[39m=\u001b[39m permutation_mappings[i]\n\u001b[1;32m    174\u001b[0m     linear_layers[i]\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m linear_layers[i]\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mdata[permutation]\n\u001b[1;32m    175\u001b[0m     \u001b[39mif\u001b[39;00m linear_layers[i]\u001b[39m.\u001b[39mbias \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from permute import match_and_permute\n",
    "valset = torch.utils.data.Subset(trainset, range(500))\n",
    "val_loader = DataLoader(valset, batch_size=100, shuffle=False)\n",
    "new_state_dict = match_and_permute(build_mlp_model, state_dict_1, state_dict_2, \n",
    "                                   val_loader, device=\"cuda\")\n",
    "\n",
    "model_1.load_state_dict(new_state_dict)\n",
    "test(model_1, test_loader, criterion, device=\"cuda\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ray",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
